{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1Urgy6v1BW1IzOI05qN48",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aamna-Khan-Git/Models/blob/main/PhonePe_transaction_insights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOUNTING DRIVE"
      ],
      "metadata": {
        "id": "VPMi6ep46K5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Giu3YkZUAPMx",
        "outputId": "c272c502-3827-4662-838a-d05de3f8da28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOADING LIBRARIES"
      ],
      "metadata": {
        "id": "-WHWzeZH6Opz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pandas matplotlib seaborn sqlalchemy\n",
        "import os\n",
        "import json\n",
        "import sqlite3\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "lNfGvkN5BfgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import os: This line imports the os module, which provides a way to interact with the operating system, such as accessing files and directories. <br>\n",
        "import json: This line imports the json module, which is used for working with JSON data (encoding and decoding).<br>\n",
        "import sqlite3: This line imports the sqlite3 module, which provides an interface for working with SQLite databases.<br>\n",
        "import pandas as pd: This line imports the pandas library, a powerful tool for data manipulation and analysis, and assigns it the alias pd for convenience."
      ],
      "metadata": {
        "id": "k7p0vRCOtHL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEFINING PATHS"
      ],
      "metadata": {
        "id": "XcwXAQJ26Rvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your cloned pulse folder in Google Drive\n",
        "base_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master\"\n",
        "\n",
        "# Ensure the directory exists before connecting to the database\n",
        "db_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix\"\n",
        "os.makedirs(db_path, exist_ok=True)\n",
        "\n",
        "# SQLite DB file will be saved in Drive\n",
        "conn = sqlite3.connect(os.path.join(db_path, \"phonepe_data.db\"))\n",
        "cursor = conn.cursor()"
      ],
      "metadata": {
        "id": "na-Kx5peBiA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "base_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master\": This line sets a variable base_path to the location of your cloned pulse folder in Google Drive. <br>\n",
        "db_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix\": This line sets a variable db_path to the directory where you want to store the SQLite database file in Google Drive.<br>\n",
        "os.makedirs(db_path, exist_ok=True): This line creates the directory specified by db_path if it doesn't already exist. The exist_ok=True argument prevents an error if the directory is already there. <br>\n",
        "conn = sqlite3.connect(os.path.join(db_path, \"phonepe_data.db\")): This line establishes a connection to a SQLite database. It uses os.path.join to create the full path to the database file named \"phonepe_data.db\" within the db_path directory. If the database file doesn't exist, it will be created. The connection object is stored in the conn variable.<br>\n",
        "cursor = conn.cursor(): This line creates a cursor object from the database connection. A cursor is used to execute SQL commands within the database. The cursor object is stored in the cursor variable."
      ],
      "metadata": {
        "id": "ScEENNBo3OCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CREATING TABLE STRUCTURE"
      ],
      "metadata": {
        "id": "itD56M2etZXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def create_phonepe_database(db_path=\"phonepe_data.db\"):\n",
        "    \"\"\"\n",
        "    Create PhonePe database with all required tables and populate them with data.\n",
        "\n",
        "    Args:\n",
        "        db_path (str): Path to the SQLite database file\n",
        "    \"\"\"\n",
        "\n",
        "    # Connect to the database\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    try:\n",
        "        print(\"Creating database tables...\")\n",
        "\n",
        "        # Create all tables\n",
        "        cursor.executescript(\"\"\"\n",
        "        -- ========================================\n",
        "        -- 1. AGGREGATED TABLES\n",
        "        -- ========================================\n",
        "\n",
        "        DROP TABLE IF EXISTS aggregated_transaction;\n",
        "        DROP TABLE IF EXISTS aggregated_user;\n",
        "        DROP TABLE IF EXISTS aggregated_insurance;\n",
        "\n",
        "        CREATE TABLE aggregated_transaction (\n",
        "            state TEXT,\n",
        "            year INTEGER,\n",
        "            quarter INTEGER,\n",
        "            transaction_type TEXT,\n",
        "            transaction_count INTEGER,\n",
        "            transaction_amount REAL\n",
        "        );\n",
        "\n",
        "        CREATE TABLE aggregated_user (\n",
        "            state TEXT,\n",
        "            year INTEGER,\n",
        "            quarter INTEGER,\n",
        "            brand TEXT,\n",
        "            user_count INTEGER,\n",
        "            percentage REAL\n",
        "        );\n",
        "\n",
        "        CREATE TABLE aggregated_insurance (\n",
        "            state TEXT,\n",
        "            year INTEGER,\n",
        "            quarter INTEGER,\n",
        "            insurance_type TEXT,\n",
        "            transaction_count INTEGER,\n",
        "            transaction_amount REAL\n",
        "        );\n",
        "\n",
        "        -- ========================================\n",
        "        -- 2. MAP TABLES\n",
        "        -- ========================================\n",
        "\n",
        "        DROP TABLE IF EXISTS map_user;\n",
        "        DROP TABLE IF EXISTS map_transaction;\n",
        "        DROP TABLE IF EXISTS map_insurance;\n",
        "\n",
        "        CREATE TABLE map_user (\n",
        "            state TEXT,\n",
        "            district TEXT,\n",
        "            year INTEGER,\n",
        "            quarter INTEGER,\n",
        "            registered_users INTEGER,\n",
        "            app_opens INTEGER\n",
        "        );\n",
        "\n",
        "        CREATE TABLE map_transaction (\n",
        "            state TEXT,\n",
        "            district TEXT,\n",
        "            year INTEGER,\n",
        "            quarter INTEGER,\n",
        "            transaction_count INTEGER,\n",
        "            transaction_amount REAL\n",
        "        );\n",
        "\n",
        "        CREATE TABLE map_insurance (\n",
        "            state TEXT,\n",
        "            district TEXT,\n",
        "            year INTEGER,\n",
        "            quarter INTEGER,\n",
        "            insurance_type TEXT,\n",
        "            transaction_count INTEGER,\n",
        "            transaction_amount REAL\n",
        "        );\n",
        "\n",
        "        -- ========================================\n",
        "        -- 3. TOP TABLES\n",
        "        -- ========================================\n",
        "\n",
        "        DROP TABLE IF EXISTS top_user;\n",
        "        DROP TABLE IF EXISTS top_transaction;\n",
        "        DROP TABLE IF EXISTS top_insurance;\n",
        "\n",
        "        CREATE TABLE top_user (\n",
        "            state TEXT,\n",
        "            year INTEGER,\n",
        "            quarter INTEGER,\n",
        "            pincode TEXT,\n",
        "            registered_users INTEGER\n",
        "        );\n",
        "\n",
        "        CREATE TABLE top_transaction (\n",
        "            state TEXT,\n",
        "            year INTEGER,\n",
        "            quarter INTEGER,\n",
        "            name TEXT, -- could be district or pincode\n",
        "            transaction_count INTEGER,\n",
        "            transaction_amount REAL\n",
        "        );\n",
        "\n",
        "        CREATE TABLE top_insurance (\n",
        "            state TEXT,\n",
        "            year INTEGER,\n",
        "            quarter INTEGER,\n",
        "            insurance_type TEXT,\n",
        "            transaction_count INTEGER,\n",
        "            transaction_amount REAL\n",
        "        );\n",
        "        \"\"\")\n",
        "\n",
        "        conn.commit()\n",
        "        print(\"All tables created successfully.\")\n",
        "\n",
        "        # Load data into tables\n",
        "        load_aggregated_data(conn)\n",
        "        load_map_data(conn)\n",
        "        load_top_data(conn)\n",
        "\n",
        "        print(\"Database setup and data loading complete!\")\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"Database error: {e}\")\n",
        "        conn.rollback()\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    finally:\n",
        "        conn.close()"
      ],
      "metadata": {
        "id": "oyv_h8a8HPjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import sqlite3, import pandas as pd, import json, import os, from pathlib import Path: These lines import necessary libraries for database operations, data manipulation, JSON handling, file system interactions, and path manipulation.<br>\n",
        "def create_phonepe_database(db_path=\"phonepe_data.db\"):: This defines the function create_phonepe_database which takes an optional argument db_path for the database file location (defaulting to \"phonepe_data.db\").<br>\n",
        "conn = sqlite3.connect(db_path): Establishes a connection to the SQLite database.<br>\n",
        "cursor = conn.cursor(): Creates a cursor object to execute SQL commands.\n",
        "try...except...finally: This block handles potential errors during database operations.<br>\n",
        "cursor.executescript(...): This executes a multi-line SQL script.<br>\n",
        "DROP TABLE IF EXISTS ...: These lines drop the tables if they already exist, ensuring a clean creation each time the script is run.<br>\n",
        "CREATE TABLE ...: These lines create the various tables (aggregated_transaction, aggregated_user, aggregated_insurance, map_user, map_transaction, map_insurance, top_user, top_transaction, top_insurance) with their respective columns and data types.<br>\n",
        "conn.commit(): Saves the changes made by the CREATE TABLE statements to the database.<br>\n",
        "load_aggregated_data(conn), load_map_data(conn), load_top_data(conn): These lines call other functions (presumably defined elsewhere in the notebook) to load data into the newly created tables.<br>\n",
        "conn.rollback(): If an error occurs within the try block, this rolls back any changes made since the last commit, preventing inconsistent data.<br>\n",
        "conn.close(): Closes the database connection in the finally block, ensuring it's always closed even if errors occur.<br>\n"
      ],
      "metadata": {
        "id": "3vNB5TQL3x1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOADING DATA FROM DRIVE TO THE AGGREGATED TABLES"
      ],
      "metadata": {
        "id": "oVuz9l_y6jVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_aggregated_data(conn):\n",
        "    \"\"\"Load data into aggregated tables\"\"\"\n",
        "    print(\"\\nLoading AGGREGATED data...\")\n",
        "\n",
        "    # AGGREGATED TRANSACTION DATA\n",
        "    print(\"  Loading aggregated_transaction...\")\n",
        "    aggregated_transaction_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/aggregated/transaction\"\n",
        "\n",
        "    # Example code to load JSON files from the aggregated transaction directory\n",
        "    for state_folder in os.listdir(aggregated_transaction_path):\n",
        "        state_path = os.path.join(aggregated_transaction_path, state_folder)\n",
        "        if os.path.isdir(state_path):\n",
        "            for year_folder in os.listdir(state_path):\n",
        "                year_path = os.path.join(state_path, year_folder)\n",
        "                if os.path.isdir(year_path):\n",
        "                    for quarter_file in os.listdir(year_path):\n",
        "                        if quarter_file.endswith('.json'):\n",
        "                            file_path = os.path.join(year_path, quarter_file)\n",
        "                            with open(file_path, 'r') as f:\n",
        "                                data = json.load(f)\n",
        "                                # Process and insert data into aggregated_transaction table\n",
        "                                process_aggregated_transaction_data(conn, data, state_folder, year_folder, quarter_file)\n",
        "\n",
        "    # AGGREGATED USER DATA\n",
        "    print(\"  Loading aggregated_user...\")\n",
        "    aggregated_user_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/aggregated/user\"\n",
        "\n",
        "    # Example code to load user data\n",
        "\n",
        "    for state_folder in os.listdir(aggregated_user_path):\n",
        "        state_path = os.path.join(aggregated_user_path, state_folder)\n",
        "        if os.path.isdir(state_path):\n",
        "            for year_folder in os.listdir(state_path):\n",
        "                year_path = os.path.join(state_path, year_folder)\n",
        "                if os.path.isdir(year_path):\n",
        "                    for quarter_file in os.listdir(year_path):\n",
        "                        if quarter_file.endswith('.json'):\n",
        "                            file_path = os.path.join(year_path, quarter_file)\n",
        "                            with open(file_path, 'r') as f:\n",
        "                                data = json.load(f)\n",
        "                                # Process and insert data into aggregated_user table\n",
        "                                process_aggregated_user_data(conn, data, state_folder, year_folder, quarter_file)\n",
        "\n",
        "\n",
        "    # AGGREGATED INSURANCE DATA\n",
        "    print(\"  Loading aggregated_insurance...\")\n",
        "    aggregated_insurance_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/aggregated/insurance\"\n",
        "\n",
        "    # Example code to load insurance data\n",
        "\n",
        "    for state_folder in os.listdir(aggregated_insurance_path):\n",
        "        state_path = os.path.join(aggregated_insurance_path, state_folder)\n",
        "        if os.path.isdir(state_path):\n",
        "            for year_folder in os.listdir(state_path):\n",
        "                year_path = os.path.join(state_path, year_folder)\n",
        "                if os.path.isdir(year_path):\n",
        "                    for quarter_file in os.listdir(year_path):\n",
        "                        if quarter_file.endswith('.json'):\n",
        "                            file_path = os.path.join(year_path, quarter_file)\n",
        "                            with open(file_path, 'r') as f:\n",
        "                                data = json.load(f)\n",
        "                                # Process and insert data into aggregated_insurance table\n",
        "                                process_aggregated_insurance_data(conn, data, state_folder, year_folder, quarter_file)\n",
        "\n",
        "\n",
        "    print(\"Aggregated data loading complete.\")"
      ],
      "metadata": {
        "id": "S4jY5URalNwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "def load_aggregated_data(conn):: This defines the function load_aggregated_data which takes the database connection object (conn) as an argument.<br>\n",
        "print(\"\\nLoading AGGREGATED data...\"): Prints a message indicating the start of aggregated data loading. <br>\n",
        "AGGREGATED TRANSACTION DATA: This section handles loading data into the aggregated_transaction table.<br>\n",
        "aggregated_transaction_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/aggregated/transaction\": Sets the path to the aggregated transaction data in your Google Drive.<br>\n",
        "for state_folder in os.listdir(aggregated_transaction_path):, for year_folder in os.listdir(state_path):, for quarter_file in os.listdir(year_path):: These nested loops iterate through the state, year, and quarter folders/files within the specified path.<br>\n",
        "if quarter_file.endswith('.json'):: Checks if the file is a JSON file.\n",
        "file_path = os.path.join(year_path, quarter_file): Constructs the full path to the JSON file.<br>\n",
        "with open(file_path, 'r') as f:: Opens the JSON file for reading.\n",
        "data = json.load(f): Loads the JSON data from the file into the data variable.<br>\n",
        "process_aggregated_transaction_data(conn, data, state_folder, year_folder, quarter_file): This line calls another function (presumably defined elsewhere) to process the loaded JSON data and insert it into the aggregated_transaction table. The state, year, and quarter information are also passed to this function.<br>\n",
        "AGGREGATED USER DATA and AGGREGATED INSURANCE DATA: These sections follow a similar structure to the aggregated transaction data section, loading data into the aggregated_user and aggregated_insurance tables respectively, using the process_aggregated_user_data and process_aggregated_insurance_data functions.<br>\n",
        "print(\"Aggregated data loading complete.\"): Prints a message indicating the completion of aggregated data loading."
      ],
      "metadata": {
        "id": "txOOt2Rj4WeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOADING DATA FROM DRIVE TO MAP TABLES"
      ],
      "metadata": {
        "id": "Ycku_idO6t3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_map_data(conn):\n",
        "    \"\"\"Load data into map tables\"\"\"\n",
        "    print(\"\\nLoading MAP data...\")\n",
        "\n",
        "    # MAP USER DATA\n",
        "    print(\"  Loading map_user...\")\n",
        "    map_user_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/map/user\"\n",
        "\n",
        "    # Example code to load map user data\n",
        "\n",
        "    for state_folder in os.listdir(map_user_path):\n",
        "        state_path = os.path.join(map_user_path, state_folder)\n",
        "        if os.path.isdir(state_path):\n",
        "            for year_folder in os.listdir(state_path):\n",
        "                year_path = os.path.join(state_path, year_folder)\n",
        "                if os.path.isdir(year_path):\n",
        "                    for quarter_file in os.listdir(year_path):\n",
        "                        if quarter_file.endswith('.json'):\n",
        "                            file_path = os.path.join(year_path, quarter_file)\n",
        "                            with open(file_path, 'r') as f:\n",
        "                                data = json.load(f)\n",
        "                                # Process and insert data into map_user table\n",
        "                                process_map_user_data(conn, data, state_folder, year_folder, quarter_file)\n",
        "\n",
        "\n",
        "    # MAP TRANSACTION DATA\n",
        "    print(\"  Loading map_transaction...\")\n",
        "    map_transaction_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/map/transaction\"\n",
        "\n",
        "    # Example code to load map transaction data\n",
        "\n",
        "    for state_folder in os.listdir(map_transaction_path):\n",
        "        state_path = os.path.join(map_transaction_path, state_folder)\n",
        "        if os.path.isdir(state_path):\n",
        "            for year_folder in os.listdir(state_path):\n",
        "                year_path = os.path.join(state_path, year_folder)\n",
        "                if os.path.isdir(year_path):\n",
        "                    for quarter_file in os.listdir(year_path):\n",
        "                        if quarter_file.endswith('.json'):\n",
        "                            file_path = os.path.join(year_path, quarter_file)\n",
        "                            with open(file_path, 'r') as f:\n",
        "                                data = json.load(f)\n",
        "                                # Process and insert data into map_transaction table\n",
        "                                process_map_transaction_data(conn, data, state_folder, year_folder, quarter_file)\n",
        "\n",
        "\n",
        "    # MAP INSURANCE DATA\n",
        "    print(\"  Loading map_insurance...\")\n",
        "    map_insurance_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/map/insurance\"\n",
        "\n",
        "    # Example code to load map insurance data\n",
        "\n",
        "    for state_folder in os.listdir(map_insurance_path):\n",
        "        state_path = os.path.join(map_insurance_path, state_folder)\n",
        "        if os.path.isdir(state_path):\n",
        "            for year_folder in os.listdir(state_path):\n",
        "                year_path = os.path.join(state_path, year_folder)\n",
        "                if os.path.isdir(year_path):\n",
        "                    for quarter_file in os.listdir(year_path):\n",
        "                        if quarter_file.endswith('.json'):\n",
        "                            file_path = os.path.join(year_path, quarter_file)\n",
        "                            with open(file_path, 'r') as f:\n",
        "                                data = json.load(f)\n",
        "                                # Process and insert data into map_insurance table\n",
        "                                process_map_insurance_data(conn, data, state_folder, year_folder, quarter_file)\n",
        "\n",
        "\n",
        "    print(\"Map data loading complete.\")\n"
      ],
      "metadata": {
        "id": "wQZeQdapqIxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "def load_map_data(conn):: This defines the function load_map_data which takes the database connection object (conn) as an argument.<br>\n",
        "print(\"\\n Loading MAP data...\"): Prints a message indicating the start of map data loading.<br>\n",
        "MAP USER DATA: This section handles loading data into the map_user table.\n",
        "map_user_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/map/user\": Sets the path to the map user data in your Google Drive.<br>\n",
        "The nested loops and file handling (os.listdir, os.path.join, endswith('.json'), open, json.load) work similarly to the load_aggregated_data function, iterating through state, year, and quarter folders/files to find JSON files.<br>\n",
        "process_map_user_data(conn, data, state_folder, year_folder, quarter_file): This line calls a function to process the loaded JSON data and insert it into the map_user table, passing the connection, data, state, year, and quarter information.<br>\n",
        "MAP TRANSACTION DATA and MAP INSURANCE DATA: These sections follow the same pattern as the map user data section, loading data into the map_transaction and map_insurance tables respectively, using the process_map_transaction_data and process_map_insurance_data functions.<br>\n",
        "print(\" Map data loading complete.\"): Prints a message indicating the completion of map data loading."
      ],
      "metadata": {
        "id": "aGL4Ipun49_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOADING DATA FROM DRIVE TO TOP TABLES"
      ],
      "metadata": {
        "id": "QgHWJ99H6yYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_top_data(conn):\n",
        "    \"\"\"Load data into top tables\"\"\"\n",
        "    print(\"\\n Loading TOP data...\")\n",
        "\n",
        "    # TOP USER DATA\n",
        "    print(\"  Loading top_user...\")\n",
        "    top_user_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/top/user\"\n",
        "\n",
        "    # Example code to load top user data\n",
        "\n",
        "    for state_folder in os.listdir(top_user_path):\n",
        "        state_path = os.path.join(top_user_path, state_folder)\n",
        "        if os.path.isdir(state_path):\n",
        "            for year_folder in os.listdir(state_path):\n",
        "                year_path = os.path.join(state_path, year_folder)\n",
        "                if os.path.isdir(year_path):\n",
        "                    for quarter_file in os.listdir(year_path):\n",
        "                        if quarter_file.endswith('.json'):\n",
        "                            file_path = os.path.join(year_path, quarter_file)\n",
        "                            with open(file_path, 'r') as f:\n",
        "                                data = json.load(f)\n",
        "                                # Process and insert data into top_user table\n",
        "                                process_top_user_data(conn, data, state_folder, year_folder, quarter_file)\n",
        "\n",
        "\n",
        "    # TOP TRANSACTION DATA\n",
        "    print(\"  Loading top_transaction...\")\n",
        "    top_transaction_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/top/transaction\"\n",
        "\n",
        "    # Example code to load top transaction data\n",
        "\n",
        "    for state_folder in os.listdir(top_transaction_path):\n",
        "        state_path = os.path.join(top_transaction_path, state_folder)\n",
        "        if os.path.isdir(state_path):\n",
        "            for year_folder in os.listdir(state_path):\n",
        "                year_path = os.path.join(state_path, year_folder)\n",
        "                if os.path.isdir(year_path):\n",
        "                    for quarter_file in os.listdir(year_path):\n",
        "                        if quarter_file.endswith('.json'):\n",
        "                            file_path = os.path.join(year_path, quarter_file)\n",
        "                            with open(file_path, 'r') as f:\n",
        "                                data = json.load(f)\n",
        "                                # Process and insert data into top_transaction table\n",
        "                                process_top_transaction_data(conn, data, state_folder, year_folder, quarter_file)\n",
        "\n",
        "\n",
        "    # TOP INSURANCE DATA\n",
        "    print(\"  Loading top_insurance...\")\n",
        "    top_insurance_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/top/insurance\"\n",
        "\n",
        "    # Example code to load top insurance data\n",
        "\n",
        "    for state_folder in os.listdir(top_insurance_path):\n",
        "        state_path = os.path.join(top_insurance_path, state_folder)\n",
        "        if os.path.isdir(state_path):\n",
        "            for year_folder in os.listdir(state_path):\n",
        "                year_path = os.path.join(state_path, year_folder)\n",
        "                if os.path.isdir(year_path):\n",
        "                    for quarter_file in os.listdir(year_path):\n",
        "                        if quarter_file.endswith('.json'):\n",
        "                            file_path = os.path.join(year_path, quarter_file)\n",
        "                            with open(file_path, 'r') as f:\n",
        "                                data = json.load(f)\n",
        "                                # Process and insert data into top_insurance table\n",
        "                                process_top_insurance_data(conn, data, state_folder, year_folder, quarter_file)\n",
        "\n",
        "\n",
        "    print(\"Top data loading complete.\")"
      ],
      "metadata": {
        "id": "ssKIXPLxqu_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "def load_top_data(conn):: This defines the function load_top_data which takes the database connection object (conn) as an argument.<br>\n",
        "print(\"\\n Loading TOP data...\"): Prints a message indicating the start of top data loading.<br>\n",
        "TOP USER DATA: This section handles loading data into the top_user table.\n",
        "top_user_path = \"/content/drive/MyDrive/Colab Notebooks/labmentix/pulse-master/data/top/user\": Sets the path to the top user data in your Google Drive.<br>\n",
        "The nested loops and file handling (os.listdir, os.path.join, endswith('.json'), open, json.load) work similarly to the previous loading functions, iterating through state, year, and quarter folders/files to find JSON files.<br>\n",
        "process_top_user_data(conn, data, state_folder, year_folder, quarter_file): This line calls a function to process the loaded JSON data and insert it into the top_user table, passing the connection, data, state, year, and quarter information.<br>\n",
        "TOP TRANSACTION DATA and TOP INSURANCE DATA: These sections follow the same pattern as the top user data section, loading data into the top_transaction and top_insurance tables respectively, using the process_top_transaction_data and process_top_insurance_data functions.<br>\n",
        "print(\"Top data loading complete.\"): Prints a message indicating the completion of top data loading.<br>\n",
        "(process_aggregated_transaction_data, process_aggregated_user_data, etc.) that are called within these loading functions to actually parse the JSON data and insert it into the database tables. Once those are defined, you can call the create_phonepe_database() function to create the database and load all the data."
      ],
      "metadata": {
        "id": "fa5ki0m95oGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DISPLAYING TOP 10 STATES"
      ],
      "metadata": {
        "id": "PO60H_PV629t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# SQL query to get top 10 states by total transaction amount\n",
        "query = \"\"\"\n",
        "SELECT state,\n",
        "       SUM(transaction_amount) AS total_amount,\n",
        "       SUM(transaction_count) AS total_transactions\n",
        "FROM aggregated_transaction\n",
        "GROUP BY state\n",
        "ORDER BY total_amount DESC\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "# Run the query\n",
        "df_top_states = pd.read_sql(query, conn)\n",
        "df_top_states\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "synPOLByrb_e",
        "outputId": "6ea2025d-9aaf-4144-93e9-cff5e28acf15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DatabaseError",
          "evalue": "Execution failed on sql '\nSELECT state, \n       SUM(transaction_amount) AS total_amount, \n       SUM(transaction_count) AS total_transactions\nFROM aggregated_transaction\nGROUP BY state\nORDER BY total_amount DESC\nLIMIT 10;\n': no such table: aggregated_transaction",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: no such table: aggregated_transaction",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-12-2585450635.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Run the query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf_top_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdf_top_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpandas_sql\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandas_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSQLiteDatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    707\u001b[0m                 \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2736\u001b[0m         \u001b[0mdtype_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDtypeBackend\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m     ) -> DataFrame | Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2739\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution failed on sql '{sql}': {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2686\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nSELECT state, \n       SUM(transaction_amount) AS total_amount, \n       SUM(transaction_count) AS total_transactions\nFROM aggregated_transaction\nGROUP BY state\nORDER BY total_amount DESC\nLIMIT 10;\n': no such table: aggregated_transaction"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lt7VwHZNrmKH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}